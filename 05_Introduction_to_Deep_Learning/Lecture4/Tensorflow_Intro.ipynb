{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1HnJf2_Eo3c"
   },
   "source": [
    "# TensorFlow \n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "colab_type": "code",
    "id": "5oTV8XEZE6E2",
    "outputId": "c1af695f-d874-4535-b859-81bd966ccd93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 977538088401586371\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5102138307915635119\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4847737241\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4014410920695305719\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13882048205496588721\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[name: \"/device:CPU:0\"\n",
       "device_type: \"CPU\"\n",
       "memory_limit: 268435456\n",
       "locality {\n",
       "}\n",
       "incarnation: 12889177116040271655\n",
       ", name: \"/device:XLA_CPU:0\"\n",
       "device_type: \"XLA_CPU\"\n",
       "memory_limit: 17179869184\n",
       "locality {\n",
       "}\n",
       "incarnation: 6191946697267366186\n",
       "physical_device_desc: \"device: XLA_CPU device\"\n",
       ", name: \"/device:GPU:0\"\n",
       "device_type: \"GPU\"\n",
       "memory_limit: 4847737241\n",
       "locality {\n",
       "  bus_id: 1\n",
       "  links {\n",
       "  }\n",
       "}\n",
       "incarnation: 9365527788988889153\n",
       "physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       ", name: \"/device:XLA_GPU:0\"\n",
       "device_type: \"XLA_GPU\"\n",
       "memory_limit: 17179869184\n",
       "locality {\n",
       "}\n",
       "incarnation: 8605089226394981138\n",
       "physical_device_desc: \"device: XLA_GPU device\"\n",
       "]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import and suppres warnings \n",
    "# ... (if you don't want to suppress them, you need to match the numpy version)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from IPython.display import Markdown, display\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(str(device_lib.list_local_devices()))\n",
    "display(Markdown(str(device_lib.list_local_devices())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BDJFFpioFLsX",
    "outputId": "0c0dd363-3b61-465f-b307-de0f036b9722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b = 101\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # verify that the math works\n",
    "    a = tf.constant(50)\n",
    "    b = tf.constant(51)\n",
    "    print(\"a + b = {0}\".format(sess.run(a + b)))\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Df2LqNoFEZf"
   },
   "source": [
    "**Eager Execution**\n",
    "\n",
    "Eager mode evaluates operations immediatley and return concrete values immediately. \n",
    "\n",
    "**Graph Execution**\n",
    "\n",
    "Graph mode was TensorFlow's default execution mode. In graph mode operations only produce a symbolic graph which doesn't get executed until run within the context of a tf.Session(). This style of coding is less inutitive and has more boilerplate, however it can lead to performance optimizations and is particularly suited for distributing training across multiple devices. We recommend using delayed execution for performance sensitive production code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LGizHFAEo3d",
    "outputId": "132a77e5-c404-4ddb-fe3d-83b8ebd91005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0OYa9jnEo3h"
   },
   "source": [
    "## Graph Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54MwJq_zEo3h"
   },
   "source": [
    "### Adding Two Tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HxbbxWQEo3i"
   },
   "source": [
    "#### Build the Graph\n",
    "\n",
    "Unlike eager mode, no concrete value will be returned yet. Just a name, shape and type are printed. Behind the scenes a directed graph is being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmEpjIPyEo3i",
    "outputId": "b128ea78-b630-4d36-9c3f-efbb988c17f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_6:0\", shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "a = tf.constant(value = [5, 3, 8], dtype = tf.int32)\n",
    "b = tf.constant(value = [3, -1, 2], dtype = tf.int32)\n",
    "c = tf.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwHYrJTGEo3l"
   },
   "source": [
    "Let's compare to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbnJeQN4Eo3l",
    "outputId": "128d605d-8a3c-4b3d-b87d-ee131311fa9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  2 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([5, 3, 8])\n",
    "b = np.array([3, -1, 2])\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcfId2BxEo3n"
   },
   "source": [
    "Numpy immediatelly executed. In lazy mode - TF did not. That is the difference between lazy and eager execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G451oaGhEo3o"
   },
   "source": [
    "#### Run the Graph\n",
    "\n",
    "A graph can be executed in the context of a `tf.compat.v1.Session()`. Think of a session as the bridge between the front-end Python API and the back-end C++ execution engine. \n",
    "\n",
    "Within a session, passing a tensor operation to `run()` will cause Tensorflow to execute all upstream operations in the graph required to calculate that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAA65UhTEo3o",
    "outputId": "3c985371-d7ea-4bd8-8c2e-5d088dc05533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  2 10]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUpTByw4Eo3q"
   },
   "source": [
    "#### Parameterizing the Graph \n",
    "\n",
    "What if values of `a` and `b` keep changing? How can you parameterize them so they can be fed in at runtime? \n",
    "\n",
    "*Step 1: Define Placeholders*\n",
    "\n",
    "Define `a` and `b` using `tf.placeholder()`. You'll need to specify the data type of the placeholder, and optionally a tensor shape.\n",
    "\n",
    "*Step 2: Provide feed_dict*\n",
    "\n",
    "Now when invoking `run()` within the `tf.Session()`, in addition to providing a tensor operation to evaluate, you also provide a dictionary whose keys are the names of the placeholders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K51TEn2lEo3q",
    "outputId": "849ba346-02ee-43d4-b1c3-64a41ed97a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6 8]\n"
     ]
    }
   ],
   "source": [
    "a = tf.compat.v1.placeholder(dtype = tf.int32, shape = [None])  \n",
    "b = tf.compat.v1.placeholder(dtype = tf.int32, shape = [None])\n",
    "c = tf.add(x = a, y = b)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(fetches = c, feed_dict = {\n",
    "        a: [3, 4, 5],\n",
    "        b: [-1, 2, 3]\n",
    "    })\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJpnX3iREo3s"
   },
   "source": [
    "## Graph execution with TF2 using functional api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQDRg2AzEo3t"
   },
   "source": [
    "The way you create a graph in TensorFlow is to use tf.function, either as a direct call or as a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELnBLsVCEo3t",
    "outputId": "40b73bd4-ed82-4d12-871a-b4b8e86b975b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart notebook before running\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# Define a Python function\n",
    "def function_to_get_faster(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Create a `Function` object that contains a graph\n",
    "a_function_that_uses_a_graph = tf.function(function_to_get_faster)\n",
    "\n",
    "# Make some tensors\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "# It just works!\n",
    "a_function_that_uses_a_graph(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6H2WyP9SEo3w",
    "outputId": "6000ecf9-5abc-4eb8-ff35-8b5b806f0016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the decorator\n",
    "@tf.function\n",
    "def function_to_get_faster(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "function_to_get_faster(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8mTBtvQEo3y"
   },
   "source": [
    "The pattern to follow is to define the training step function, that's the most computationally intensive function, and decorate it with @tf.function: only use tf.function to decorate high-level computations - for example, one step of training, or the forward pass of your model.\n",
    "\n",
    "https://stackoverflow.com/a/55279561/1964707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSY266dIEo3y"
   },
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A0eoNYLKEo3y",
    "outputId": "e707ac24-be27-4ff8-f440-690f9f292db5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart notebook before running\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QlGseHNEo30"
   },
   "source": [
    "Now you can run TensorFlow operations and the results will return immediately (no sessions required):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0IROzdjEo31",
    "outputId": "c76a9ab7-11f3-4279-b266-8033a1333b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [[4.]]\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)\n",
    "print(\"Result: {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3w5aVG2LEo33"
   },
   "source": [
    "Enabling eager execution changes how TensorFlow operations behave—now they immediately evaluate and return their values to Python. tf.Tensor objects reference concrete values instead of symbolic handles to nodes in a computational graph. Since there isn't a computational graph to build and run later in a session, it's easy to inspect results using print() or a debugger. Evaluating, printing, and checking tensor values does not break the flow for computing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yr1y3O4eEo33"
   },
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WHmdnjJEo33"
   },
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V18l7xshEo34"
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1.0, 2.0]])\n",
    "b = tf.constant([[4.0, 3.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rKZMguiZEo35"
   },
   "source": [
    "### Operator overloading is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxJFWWKGEo36",
    "outputId": "cad8bda4-76b2-4572-9c7a-f1f9640df194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4. 6.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[5. 5.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[-3. -1.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[0.25      0.6666667]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[10.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(a * b)\n",
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a / b)\n",
    "print(a @ tf.transpose(b)) # matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqLW0GIpEo38"
   },
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCk7B4mKEo38",
    "outputId": "2cb69430-f18b-4dc6-84b2-5536640da9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[4. 3.]]\n",
      "\n",
      " [[4. 3.]]], shape=(2, 1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[4. 3.]]\n",
      "\n",
      "  [[4. 3.]]]\n",
      "\n",
      "\n",
      " [[[4. 3.]]\n",
      "\n",
      "  [[4. 3.]]]], shape=(2, 2, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "stacked1 = tf.stack([b, b])\n",
    "print(stacked1)\n",
    "\n",
    "stacked2 = tf.stack([stacked1, stacked1])\n",
    "print(stacked2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PnL918VEo3-"
   },
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJ2Dc5XlEo3_",
    "outputId": "5dde36e7-b625-48e8-953a-01176750faee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "non_sliced = tf.constant([[1, 2, 3],[4, 5, 6]])\n",
    "# sliced = non_sliced[:,2]\n",
    "# sliced = non_sliced[0,1]\n",
    "# sliced = non_sliced[:]\n",
    "# [[1 2 3]\n",
    "# [4 5 6]]\n",
    "# sliced = non_sliced[:,2:3]\n",
    "# sliced = non_sliced[0:1,0:3]\n",
    "print(sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2_-LsqaEo4A"
   },
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZ2ghBe1Eo4B"
   },
   "source": [
    "Given tensor, this operation returns a new tf.Tensor that has the same values as tensor in the same order, except with a new shape given by shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyTAr9MaEo4B",
    "outputId": "f7b76584-d80b-4644-8fa7-9bde63e73f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = [[1, 2, 3],[4, 5, 6]]\n",
    "print(type(t1)) # python list\n",
    "print(tf.shape(t1))\n",
    "\n",
    "t2 = tf.reshape(t1, [6])\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezzdIeCxEo4E"
   },
   "source": [
    "The tf.reshape does not change the order of or the total number of elements in the tensor, and so it can reuse the underlying data buffer. This makes it a fast operation independent of how big of a tensor it is operating on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8I0IRRTEo4E"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 4 values, but the requested shape has 2 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8072\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8073\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   8074\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Reshape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-649a5ab50aee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m   \"\"\"\n\u001b[1;32m--> 193\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8077\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8078\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8079\u001b[1;33m         return reshape_eager_fallback(\n\u001b[0m\u001b[0;32m   8080\u001b[0m             tensor, shape, name=name, ctx=_ctx)\n\u001b[0;32m   8081\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m   8104\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8105\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tshape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8106\u001b[1;33m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0m\u001b[0;32m   8107\u001b[0m                              ctx=ctx, name=name)\n\u001b[0;32m   8108\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 4 values, but the requested shape has 2 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "tf.reshape([1, 2, 3, 4], [2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7KXUEp9Eo4G"
   },
   "source": [
    "InvalidArgumentError: Input to reshape is a tensor with 3 values, but the requested shape has 4 [Op:Reshape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6-41zWdEo4G"
   },
   "source": [
    "<h2> Heron's Formula in TensorFlow </h2>\n",
    "\n",
    "The area of triangle whose three sides are $(a, b, c)$ is $\\sqrt{s(s-a)(s-b)(s-c)}$ where $s=\\frac{a+b+c}{2}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDps-fRyEo4H",
    "outputId": "f7ae5ecf-f7bc-4869-ed24-5935af5a84d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.278497 4.709139]\n"
     ]
    }
   ],
   "source": [
    "def compute_area(sides):\n",
    "    # slice the input to get the sides\n",
    "    a = sides[:,0]  # 5.0, 2.3\n",
    "    b = sides[:,1]  # 3.0, 4.1\n",
    "    c = sides[:,2]  # 7.1, 4.8\n",
    "\n",
    "    # Heron's formula\n",
    "    s = (a + b + c) * 0.5   # (a + b) is a short-cut to tf.add(a, b)\n",
    "    # s = tf.multiply(tf.add(tf.add(a, b), c),  0.5)\n",
    "    areasq = s * (s - a) * (s - b) * (s - c) # (a * b) is a short-cut to tf.multiply(a, b), not tf.matmul(a, b)\n",
    "    return tf.sqrt(areasq)\n",
    "\n",
    "\n",
    "# pass in two triangles\n",
    "area = compute_area(tf.constant([\n",
    "  [5.0, 3.0, 7.1],\n",
    "  [2.3, 4.1, 4.8]\n",
    "]))\n",
    "print(area.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dijpYyBsEo4I"
   },
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "glVHdM6aEo4J"
   },
   "source": [
    "### Error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpNJ4BbYEo4J"
   },
   "outputs": [],
   "source": [
    "def method(data):\n",
    "    a = data[:,0:2]\n",
    "    b = data[:,1]\n",
    "    c = a + b\n",
    "    print(b.get_shape())\n",
    "    return tf.matmul(c, tf.transpose(c))\n",
    "\n",
    "print(method(tf.constant([\n",
    "    [5.0, 3.0, 7.1],\n",
    "    [2.3, 4.1, 4.8],\n",
    "    [2.3, 4.1, 4.8]\n",
    "])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOG6S2SPEo4K"
   },
   "source": [
    "Incompatible shapes: [3,2] vs. [3] [Op:AddV2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaszSIJjEo4L"
   },
   "source": [
    "### Method isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZBPIWLqEo4L"
   },
   "source": [
    "### Made up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsiWVPGUEo4L"
   },
   "source": [
    "### Common problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAyepq4cEo4M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Tensorflow Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
